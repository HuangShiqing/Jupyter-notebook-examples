{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorlayer as tl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper function to load images information (image_path, image_label)\n",
    "def load_image_path(data_path, valid_proportion, test_proportion):\n",
    "    pos_image_path = []\n",
    "    pos_labels = []\n",
    "\n",
    "    neg_image_path = []\n",
    "    neg_labels = []\n",
    "\n",
    "    ful_image_path = []\n",
    "    ful_labels = []\n",
    "\n",
    "    np.random.seed(0)\n",
    "\n",
    "    pos_path = data_path + \"1/\"\n",
    "    for img in tf.gfile.ListDirectory(pos_path):\n",
    "        # if '.bmp' not in img:\n",
    "        #    continue\n",
    "\n",
    "        label = 1\n",
    "\n",
    "        path = os.path.join(pos_path, img)\n",
    "        pos_image_path.append(path)\n",
    "        pos_labels.append(label)\n",
    "\n",
    "    neg_path = data_path + \"0/\"\n",
    "    for img in tf.gfile.ListDirectory(neg_path):\n",
    "        # if '.bmp' not in img:\n",
    "        #    continue\n",
    "\n",
    "        label = 0\n",
    "\n",
    "        path = os.path.join(neg_path, img)\n",
    "        neg_image_path.append(path)\n",
    "        neg_labels.append(label)\n",
    "\n",
    "    ful_image_path = pos_image_path + neg_image_path\n",
    "    ful_labels = pos_labels + neg_labels\n",
    "\n",
    "    temp = np.array([ful_image_path, ful_labels])\n",
    "    temp = temp.transpose()\n",
    "    np.random.shuffle(temp)\n",
    "    ful_image_path = list(temp[:, 0])\n",
    "    ful_labels = list(temp[:, 1])\n",
    "    ful_labels = [int(i) for i in ful_labels]\n",
    "\n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(ful_image_path, ful_labels,\n",
    "                                                          test_size=(valid_proportion + test_proportion),\n",
    "                                                          stratify=ful_labels, random_state=1)\n",
    "    x_valid, x_test, y_valid, y_test = train_test_split(x_valid, y_valid, test_size=test_proportion / (\n",
    "            valid_proportion + test_proportion), stratify=y_valid, random_state=1)\n",
    "\n",
    "    print(\"train_num: %d ,pos_num: %d , neg_num: %d\" % (\n",
    "        len(y_train), count_pos(y_train), len(y_train) - count_pos(y_train)))\n",
    "    print(\"valid_num: %d ,pos_num: %d , neg_num: %d\" % (\n",
    "        len(y_valid), count_pos(y_valid), len(y_valid) - count_pos(y_valid)))\n",
    "    print(\"test_num : %d ,pos_num: %d , neg_num: %d\" % (\n",
    "        len(y_test), count_pos(y_test), len(y_test) - count_pos(y_test)))\n",
    "\n",
    "    return x_train, y_train, x_valid, y_valid, x_test, y_test\n",
    "\n",
    "\n",
    "def count_pos(lables):\n",
    "    num = 0\n",
    "    for i in range(len(lables)):\n",
    "        if lables[i] == 1:\n",
    "            num = num + 1\n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Train_Proportion = 0.8  # Proportion of the data to be used for training\n",
    "Valid_Proportion = 0.1\n",
    "Test_Proportion = 0.1  #\n",
    "data_dir = \"F:/Github/clone/image_food_classification/datasets/food_101_dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_num: 3593 ,pos_num: 757 , neg_num: 2836\n",
      "valid_num: 449 ,pos_num: 95 , neg_num: 354\n",
      "test_num : 450 ,pos_num: 95 , neg_num: 355\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_valid, y_valid, x_test, y_test = load_image_path(data_dir, Valid_Proportion,Test_Proportion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "上面是图片路径和标签的获取，在另外的例程里有详细介绍\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F:/Github/clone/image_food_classification/datasets/food_101_dataset/0/club_sandwich_65.jpg', 'F:/Github/clone/image_food_classification/datasets/food_101_dataset/0/club_sandwich_767.jpg']\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "输入的格式，x是图片的绝对路径，字符串组成的列表\n",
    "            y是标签值，0或者1，int组成的列表\n",
    "'''\n",
    "x = x_test[0:10]\n",
    "y = y_test[0:10]\n",
    "print(x[:2])\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch(x, y, image_W, image_H, batch_size, capacity=500, epochs = None):\n",
    "    '''\n",
    "    Args:\n",
    "        x: list type\n",
    "        y: list type\n",
    "        image_W: image width\n",
    "        image_H: image height\n",
    "        batch_size: batch size\n",
    "        capacity: the maximum elements in queue\n",
    "        epochs: 如果要指定epoch数\n",
    "    Returns:\n",
    "        image_batch: 4D tensor [batch_size, width, height, 3], dtype=tf.float32\n",
    "        label_batch: 1D tensor [batch_size], dtype=tf.int32\n",
    "    '''\n",
    "\n",
    "    x = tf.cast(x, tf.string)\n",
    "    y = tf.cast(y, tf.int32)\n",
    "\n",
    "    # make an input queue\n",
    "    input_queue = tf.train.slice_input_producer([x, y],num_epochs=epochs)\n",
    "\n",
    "    label = input_queue[1]\n",
    "    image_contents = tf.read_file(input_queue[0])\n",
    "    image = tf.image.decode_jpeg(image_contents, channels=3)\n",
    "\n",
    "    ######################################\n",
    "    # data argumentation should go to here\n",
    "    ######################################\n",
    "\n",
    "    image = tf.image.resize_images(image, [image_W, image_H], method=0)\n",
    "    # image = tf.image.resize_image_with_crop_or_pad(image, image_W, image_H)\n",
    "    # if you want to test the generated batches of images, you might want to comment the following line.\n",
    "    # 如果想看到正常的图片，请注释掉111行（标准化）和 126行（image_batch = tf.cast(image_batch, tf.float32)）\n",
    "    # 训练时不要注释掉！\n",
    "    image = tf.image.per_image_standardization(image)\n",
    "\n",
    "    image_batch, label_batch = tf.train.batch([image, label],\n",
    "                                              batch_size=batch_size,\n",
    "                                              num_threads=64,\n",
    "                                              capacity=capacity)\n",
    "\n",
    "    image_batch = tf.cast(image_batch, tf.float32)\n",
    "    label_batch = tf.reshape(label_batch, [batch_size])\n",
    "\n",
    "    # label_batch = to_categorical(y=label_batch, nb_classes=2)\n",
    "    return image_batch, label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0]\n",
      "[0 0 0]\n",
      "[0 0 0]\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "如果我指定获取batch的epoch是1，batch_size是3，那么10条数据只获得3个batch，在尝试获取第四个batch的时候就超出范围了就抛出异常了。\n",
    "'''\n",
    "test_batch_run, test_label_batch_run = get_batch(x,y,208,208,batch_size=3,epochs=1)\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    tf.local_variables_initializer().run()#虽然好像没有用到变量，但是用到tf.train.batch就要加这句话\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "   \n",
    "    try:\n",
    "        while not coord.should_stop() :\n",
    "           \n",
    "            img, label = sess.run([test_batch_run, test_label_batch_run])\n",
    "            print(label)\n",
    "           \n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('done!')\n",
    "    finally:\n",
    "        coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0]\n",
      "[0 0 0]\n",
      "[0 0 0]\n",
      "[0 0 0]\n",
      "[0 0 0]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "如果我不指定获取batch的epoch，只指定batch_size是3，那么10条数据就会不断循环，不断获取size是3的batch。这里我是用i来限定5次循环读取batch\n",
    "'''\n",
    "test_batch_run, test_label_batch_run = get_batch(x,y,208,208,batch_size=3)\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    tf.local_variables_initializer().run()#虽然好像没有用到变量，但是用到tf.train.batch就要加这句话\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    i = 0\n",
    "    try:\n",
    "        while not coord.should_stop() and i<5:\n",
    "           \n",
    "            img, label = sess.run([test_batch_run, test_label_batch_run])\n",
    "            print(label)\n",
    "            i += 1 \n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('done!')\n",
    "    finally:\n",
    "        coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
