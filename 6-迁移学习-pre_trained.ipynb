{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorlayer as tl\n",
    "from tensorlayer.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  # dealing with plots \n",
    "import os\n",
    "from scipy.misc import imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_image_path(data_path, valid_proportion, test_proportion, pos_path=\"1/\", neg_path=\"0/\"):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        data_path: list,数据所在文件夹，最后有一杠\n",
    "        valid_proportion: float，验证集所占百分比，小数，如0.1\n",
    "        test_proportion: float，测试集所占百分比\n",
    "        pos_path: str,正样本所在文件夹\n",
    "        neg_path: str,负样本所在文件夹\n",
    "    Returns:\n",
    "        x_train: list，dtype=str，图片路径\n",
    "        y_train: list, dtype=int\n",
    "        x_valid: list，dtype=str，图片路径\n",
    "        y_valid: list, dtype=int\n",
    "        x_test: list，dtype=str，图片路径\n",
    "        y_test: list, dtype=int\n",
    "    \"\"\"\n",
    "\n",
    "    pos_image_path = []\n",
    "    pos_labels = []\n",
    "\n",
    "    neg_image_path = []\n",
    "    neg_labels = []\n",
    "\n",
    "    ful_image_path = []\n",
    "    ful_labels = []\n",
    "\n",
    "    np.random.seed(0)\n",
    "\n",
    "    pos_path = data_path + pos_path\n",
    "    for img in tf.gfile.ListDirectory(pos_path):\n",
    "        label = 1\n",
    "\n",
    "        path = os.path.join(pos_path, img)\n",
    "        pos_image_path.append(path)\n",
    "        pos_labels.append(label)\n",
    "\n",
    "    neg_path = data_path + neg_path\n",
    "    for img in tf.gfile.ListDirectory(neg_path):\n",
    "        label = 0\n",
    "\n",
    "        path = os.path.join(neg_path, img)\n",
    "        neg_image_path.append(path)\n",
    "        neg_labels.append(label)\n",
    "\n",
    "    ful_image_path = pos_image_path + neg_image_path\n",
    "    ful_labels = pos_labels + neg_labels\n",
    "\n",
    "    temp = np.array([ful_image_path, ful_labels])\n",
    "    temp = temp.transpose()\n",
    "    np.random.shuffle(temp)\n",
    "    ful_image_path = list(temp[:, 0])\n",
    "    ful_labels = list(temp[:, 1])\n",
    "    ful_labels = [int(i) for i in ful_labels]\n",
    "\n",
    "    x_valid = []\n",
    "    y_valid = []\n",
    "    x_test = []\n",
    "    y_test = []\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    if not valid_proportion == 0:\n",
    "        x_train, x_valid, y_train, y_valid = train_test_split(ful_image_path, ful_labels,\n",
    "                                                              test_size=(valid_proportion + test_proportion),\n",
    "                                                              stratify=ful_labels, random_state=1)\n",
    "        if not test_proportion == 0:\n",
    "            x_valid, x_test, y_valid, y_test = train_test_split(x_valid, y_valid, test_size=test_proportion / (\n",
    "                    valid_proportion + test_proportion), stratify=y_valid, random_state=1)\n",
    "    else:\n",
    "        x_train = ful_image_path\n",
    "        y_train = ful_labels\n",
    "\n",
    "    print(\"train_num: %d ,pos_num: %d , neg_num: %d\" % (\n",
    "        len(y_train), y_train.count(1), len(y_train) - y_train.count(1)))\n",
    "    print(\"valid_num: %d ,pos_num: %d , neg_num: %d\" % (\n",
    "        len(y_valid), y_valid.count(1), len(y_valid) - y_valid.count(1)))\n",
    "    print(\"test_num : %d ,pos_num: %d , neg_num: %d\" % (\n",
    "        len(y_test), y_test.count(1), len(y_test) - y_test.count(1)))\n",
    "\n",
    "    return x_train, y_train, x_valid, y_valid, x_test, y_test\n",
    "\n",
    "\n",
    "def get_batch(x, y, image_W, image_H, batch_size, capacity=500, epochs=None):\n",
    "    '''\n",
    "    Args:\n",
    "        x: list type\n",
    "        y: list type\n",
    "        image_W: image width\n",
    "        image_H: image height\n",
    "        batch_size: batch size\n",
    "        capacity: the maximum elements in queue\n",
    "        epochs: 如果要指定epoch数\n",
    "    Returns:\n",
    "        image_batch: 4D tensor [batch_size, width, height, 3], dtype=tf.float32\n",
    "        label_batch: 1D tensor [batch_size], dtype=tf.int32\n",
    "    '''\n",
    "\n",
    "    x = tf.cast(x, tf.string)\n",
    "    y = tf.cast(y, tf.int32)\n",
    "\n",
    "    # make an input queue\n",
    "    input_queue = tf.train.slice_input_producer([x, y], num_epochs=epochs)\n",
    "\n",
    "    label = input_queue[1]\n",
    "    image_contents = tf.read_file(input_queue[0])\n",
    "    image = tf.image.decode_jpeg(image_contents, channels=3)\n",
    "\n",
    "    ######################################\n",
    "    # data argumentation should go to here\n",
    "    ######################################\n",
    "\n",
    "    image = tf.image.resize_images(image, [image_W, image_H], method=0)\n",
    "    # image = tf.image.resize_image_with_crop_or_pad(image, image_W, image_H)\n",
    "    # if you want to test the generated batches of images, you might want to comment the following line.\n",
    "    # 如果想看到正常的图片，请注释掉111行（标准化）和 126行（image_batch = tf.cast(image_batch, tf.float32)）\n",
    "    # 训练时不要注释掉！\n",
    "    image = tf.image.per_image_standardization(image)\n",
    "\n",
    "    image_batch, label_batch = tf.train.batch([image, label],\n",
    "                                              batch_size=batch_size,\n",
    "                                              num_threads=64,\n",
    "                                              capacity=capacity)\n",
    "\n",
    "    image_batch = tf.cast(image_batch, tf.float32)\n",
    "    label_batch = tf.reshape(label_batch, [batch_size])\n",
    "\n",
    "    # label_batch = to_categorical(y=label_batch, nb_classes=2)\n",
    "    return image_batch, label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_num: 4042 ,pos_num: 852 , neg_num: 3190\n",
      "valid_num: 450 ,pos_num: 95 , neg_num: 355\n",
      "test_num : 0 ,pos_num: 0 , neg_num: 0\n"
     ]
    }
   ],
   "source": [
    "Train_Proportion = 0.9  # Proportion of the data to be used for training\n",
    "Valid_Proportion = 0.1\n",
    "Test_Proportion = 0  #\n",
    "data_dir = \"F:/Python/data/food_101_dataset/\"\n",
    "x_train, y_train, x_valid, y_valid, x_test, y_test = load_image_path(data_dir, Valid_Proportion,\n",
    "                                                                                Test_Proportion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#写了一个函数，用来自动获取batchsize的合适值。使得total_num % batchsize = 0\n",
    "def get_batch_size(x):\n",
    "    #首先求出因数\n",
    "    div = []\n",
    "    i = 1\n",
    "    while i <= x :\n",
    "        if x % i == 0:\n",
    "            div.append(i)\n",
    "        i += 1    \n",
    "    #把因数list反转，然后找一个最好是100到300之间的最大值，没有那就0到100之间的最大值。都没有就raise\n",
    "    div.reverse()\n",
    "    for b in div:\n",
    "        if b - 100 < 200 or 100 - b >0 :\n",
    "            return b\n",
    "\n",
    "    raise NameError(\"No such Number\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batchsize : 94\n"
     ]
    }
   ],
   "source": [
    "#注意，这里要把epoch设置成1\n",
    "batch_size = get_batch_size(len(y_train))\n",
    "print(\"batchsize : \" + str(batch_size))\n",
    "train_batch_run, train_label_batch_run = get_batch(x_train, y_train, 224, 224, batch_size, capacity=500, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre_trained_dir = \"F:/Python/pre-trained/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg_16/fc8/weights  :  [1, 1, 4096, 1000]\n",
      "vgg_16/fc7/biases  :  [4096]\n",
      "vgg_16/fc7/weights  :  [1, 1, 4096, 4096]\n",
      "vgg_16/fc6/weights  :  [7, 7, 512, 4096]\n",
      "vgg_16/fc8/biases  :  [1000]\n",
      "vgg_16/fc6/biases  :  [4096]\n"
     ]
    }
   ],
   "source": [
    "#查看vgg的网络结构\n",
    "\n",
    "#创建一个读写器\n",
    "reader = tf.train.NewCheckpointReader(checkpoint_dir + \"vgg_16.ckpt\")\n",
    "#读变量和shape的映射字典\n",
    "all_variables_shape = reader.get_variable_to_shape_map()\n",
    "#读变量和dtyte的映射字典\n",
    "all_variables_dtyte = reader.get_variable_to_dtype_map()\n",
    "\n",
    "for variable in all_variables_shape:\n",
    "    #如果要看全部的变量就把下面这个if注释掉\n",
    "    if \"fc\" in variable:\n",
    "        print(variable,\" : \",all_variables_shape[variable])\n",
    "# print(all_variables_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#定义一个VGG16的网络\n",
    "def model(input):\n",
    "    network = tl.layers.InputLayer(input, name='input')\n",
    "    # conv1\n",
    "    network = Conv2dLayer(\n",
    "        network,\n",
    "        act=tf.nn.relu,\n",
    "        shape=[3, 3, 3, 64],  # 64 features for each 3x3 patch\n",
    "        strides=[1, 1, 1, 1],\n",
    "        padding='SAME',\n",
    "        name='conv1_1')\n",
    "    network = Conv2dLayer(\n",
    "        network,\n",
    "        act=tf.nn.relu,\n",
    "        shape=[3, 3, 64, 64],  # 64 features for each 3x3 patch\n",
    "        strides=[1, 1, 1, 1],\n",
    "        padding='SAME',\n",
    "        name='conv1_2')\n",
    "    network = PoolLayer(network, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', pool=tf.nn.max_pool, name='pool1')\n",
    "\n",
    "    # conv2\n",
    "    network = Conv2dLayer(\n",
    "        network,\n",
    "        act=tf.nn.relu,\n",
    "        shape=[3, 3, 64, 128],  # 128 features for each 3x3 patch\n",
    "        strides=[1, 1, 1, 1],\n",
    "        padding='SAME',\n",
    "        name='conv2_1')\n",
    "    network = Conv2dLayer(\n",
    "        network,\n",
    "        act=tf.nn.relu,\n",
    "        shape=[3, 3, 128, 128],  # 128 features for each 3x3 patch\n",
    "        strides=[1, 1, 1, 1],\n",
    "        padding='SAME',\n",
    "        name='conv2_2')\n",
    "    network = PoolLayer(network, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', pool=tf.nn.max_pool, name='pool2')\n",
    "\n",
    "    # conv3\n",
    "    network = Conv2dLayer(\n",
    "        network,\n",
    "        act=tf.nn.relu,\n",
    "        shape=[3, 3, 128, 256],  # 256 features for each 3x3 patch\n",
    "        strides=[1, 1, 1, 1],\n",
    "        padding='SAME',\n",
    "        name='conv3_1')\n",
    "    network = Conv2dLayer(\n",
    "        network,\n",
    "        act=tf.nn.relu,\n",
    "        shape=[3, 3, 256, 256],  # 256 features for each 3x3 patch\n",
    "        strides=[1, 1, 1, 1],\n",
    "        padding='SAME',\n",
    "        name='conv3_2')\n",
    "    network = Conv2dLayer(\n",
    "        network,\n",
    "        act=tf.nn.relu,\n",
    "        shape=[3, 3, 256, 256],  # 256 features for each 3x3 patch\n",
    "        strides=[1, 1, 1, 1],\n",
    "        padding='SAME',\n",
    "        name='conv3_3')\n",
    "    network = PoolLayer(network, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', pool=tf.nn.max_pool, name='pool3')\n",
    "\n",
    "    # conv4\n",
    "    network = Conv2dLayer(\n",
    "        network,\n",
    "        act=tf.nn.relu,\n",
    "        shape=[3, 3, 256, 512],  # 512 features for each 3x3 patch\n",
    "        strides=[1, 1, 1, 1],\n",
    "        padding='SAME',\n",
    "        name='conv4_1')\n",
    "    network = Conv2dLayer(\n",
    "        network,\n",
    "        act=tf.nn.relu,\n",
    "        shape=[3, 3, 512, 512],  # 512 features for each 3x3 patch\n",
    "        strides=[1, 1, 1, 1],\n",
    "        padding='SAME',\n",
    "        name='conv4_2')\n",
    "    network = Conv2dLayer(\n",
    "        network,\n",
    "        act=tf.nn.relu,\n",
    "        shape=[3, 3, 512, 512],  # 512 features for each 3x3 patch\n",
    "        strides=[1, 1, 1, 1],\n",
    "        padding='SAME',\n",
    "        name='conv4_3')\n",
    "    network = PoolLayer(network, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', pool=tf.nn.max_pool, name='pool4')\n",
    "\n",
    "    # conv5\n",
    "    network = Conv2dLayer(\n",
    "        network,\n",
    "        act=tf.nn.relu,\n",
    "        shape=[3, 3, 512, 512],  # 512 features for each 3x3 patch\n",
    "        strides=[1, 1, 1, 1],\n",
    "        padding='SAME',\n",
    "        name='conv5_1')\n",
    "    network = Conv2dLayer(\n",
    "        network,\n",
    "        act=tf.nn.relu,\n",
    "        shape=[3, 3, 512, 512],  # 512 features for each 3x3 patch\n",
    "        strides=[1, 1, 1, 1],\n",
    "        padding='SAME',\n",
    "        name='conv5_2')\n",
    "    network = Conv2dLayer(\n",
    "        network,\n",
    "        act=tf.nn.relu,\n",
    "        shape=[3, 3, 512, 512],  # 512 features for each 3x3 patch\n",
    "        strides=[1, 1, 1, 1],\n",
    "        padding='SAME',\n",
    "        name='conv5_3')\n",
    "    network = PoolLayer(network, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', pool=tf.nn.max_pool, name='pool5')\n",
    "    network = FlattenLayer(network, name='flatten')\n",
    "    network = DenseLayer(network, n_units=4096, act=tf.nn.relu, name='fc6_relu')\n",
    "    network = DenseLayer(network, n_units=4096, act=tf.nn.relu, name='fc7_relu')\n",
    "    y = network.outputs\n",
    "    return  y, network\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [TL] InputLayer  input: (94, 224, 224, 3)\n",
      "  [TL] Conv2dLayer conv1_1: shape:[3, 3, 3, 64] strides:[1, 1, 1, 1] pad:SAME act:relu\n",
      "  [TL] Conv2dLayer conv1_2: shape:[3, 3, 64, 64] strides:[1, 1, 1, 1] pad:SAME act:relu\n",
      "  [TL] PoolLayer   pool1: ksize:[1, 2, 2, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n",
      "  [TL] Conv2dLayer conv2_1: shape:[3, 3, 64, 128] strides:[1, 1, 1, 1] pad:SAME act:relu\n",
      "  [TL] Conv2dLayer conv2_2: shape:[3, 3, 128, 128] strides:[1, 1, 1, 1] pad:SAME act:relu\n",
      "  [TL] PoolLayer   pool2: ksize:[1, 2, 2, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n",
      "  [TL] Conv2dLayer conv3_1: shape:[3, 3, 128, 256] strides:[1, 1, 1, 1] pad:SAME act:relu\n",
      "  [TL] Conv2dLayer conv3_2: shape:[3, 3, 256, 256] strides:[1, 1, 1, 1] pad:SAME act:relu\n",
      "  [TL] Conv2dLayer conv3_3: shape:[3, 3, 256, 256] strides:[1, 1, 1, 1] pad:SAME act:relu\n",
      "  [TL] PoolLayer   pool3: ksize:[1, 2, 2, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n",
      "  [TL] Conv2dLayer conv4_1: shape:[3, 3, 256, 512] strides:[1, 1, 1, 1] pad:SAME act:relu\n",
      "  [TL] Conv2dLayer conv4_2: shape:[3, 3, 512, 512] strides:[1, 1, 1, 1] pad:SAME act:relu\n",
      "  [TL] Conv2dLayer conv4_3: shape:[3, 3, 512, 512] strides:[1, 1, 1, 1] pad:SAME act:relu\n",
      "  [TL] PoolLayer   pool4: ksize:[1, 2, 2, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n",
      "  [TL] Conv2dLayer conv5_1: shape:[3, 3, 512, 512] strides:[1, 1, 1, 1] pad:SAME act:relu\n",
      "  [TL] Conv2dLayer conv5_2: shape:[3, 3, 512, 512] strides:[1, 1, 1, 1] pad:SAME act:relu\n",
      "  [TL] Conv2dLayer conv5_3: shape:[3, 3, 512, 512] strides:[1, 1, 1, 1] pad:SAME act:relu\n",
      "  [TL] PoolLayer   pool5: ksize:[1, 2, 2, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n",
      "  [TL] FlattenLayer flatten: 25088\n",
      "  [TL] DenseLayer  fc6_relu: 4096 relu\n",
      "  [TL] DenseLayer  fc7_relu: 4096 relu\n"
     ]
    }
   ],
   "source": [
    "#进行inference\n",
    "#要注意一点就是，当从tf.train.batch获得batch和batch_label后，我可以对其中一个进行计算，比如下面的\n",
    "#model，将batch变成y_。不管我怎么叠加运算，只要我不对其中任何一个进行run，最后再同时run，就都是对应的两个变量\n",
    "y_, net = model(train_batch_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#因为第一种迁移学习就是不改变前面的变量，只去掉最后一层全连接层。所以要载入模型的时候要有选择的载入。需要准备\n",
    "#一个list或者dict，指定需要载入哪些变量\n",
    "def prepare():\n",
    "    conv1_1_W_conv2d = tf.get_default_graph().get_tensor_by_name(\"conv1_1/W_conv2d:0\")\n",
    "    conv1_1_b_conv2d = tf.get_default_graph().get_tensor_by_name(\"conv1_1/b_conv2d:0\")\n",
    "    conv1_2_W_conv2d = tf.get_default_graph().get_tensor_by_name(\"conv1_2/W_conv2d:0\")\n",
    "    conv1_2_b_conv2d = tf.get_default_graph().get_tensor_by_name(\"conv1_2/b_conv2d:0\")\n",
    "\n",
    "    conv2_1_W_conv2d = tf.get_default_graph().get_tensor_by_name(\"conv2_1/W_conv2d:0\")\n",
    "    conv2_1_b_conv2d = tf.get_default_graph().get_tensor_by_name(\"conv2_1/b_conv2d:0\")\n",
    "    conv2_2_W_conv2d = tf.get_default_graph().get_tensor_by_name(\"conv2_2/W_conv2d:0\")\n",
    "    conv2_2_b_conv2d = tf.get_default_graph().get_tensor_by_name(\"conv2_2/b_conv2d:0\")\n",
    "\n",
    "    conv3_1_W_conv2d = tf.get_default_graph().get_tensor_by_name(\"conv3_1/W_conv2d:0\")\n",
    "    conv3_1_b_conv2d = tf.get_default_graph().get_tensor_by_name(\"conv3_1/b_conv2d:0\")\n",
    "    conv3_2_W_conv2d = tf.get_default_graph().get_tensor_by_name(\"conv3_2/W_conv2d:0\")\n",
    "    conv3_2_b_conv2d = tf.get_default_graph().get_tensor_by_name(\"conv3_2/b_conv2d:0\")\n",
    "    conv3_3_W_conv2d = tf.get_default_graph().get_tensor_by_name(\"conv3_3/W_conv2d:0\")\n",
    "    conv3_3_b_conv2d = tf.get_default_graph().get_tensor_by_name(\"conv3_3/b_conv2d:0\")\n",
    "\n",
    "    conv4_1_W_conv2d = tf.get_default_graph().get_tensor_by_name(\"conv4_1/W_conv2d:0\")\n",
    "    conv4_1_b_conv2d = tf.get_default_graph().get_tensor_by_name(\"conv4_1/b_conv2d:0\")\n",
    "    conv4_2_W_conv2d = tf.get_default_graph().get_tensor_by_name(\"conv4_2/W_conv2d:0\")\n",
    "    conv4_2_b_conv2d = tf.get_default_graph().get_tensor_by_name(\"conv4_2/b_conv2d:0\")\n",
    "    conv4_3_W_conv2d = tf.get_default_graph().get_tensor_by_name(\"conv4_3/W_conv2d:0\")\n",
    "    conv4_3_b_conv2d = tf.get_default_graph().get_tensor_by_name(\"conv4_3/b_conv2d:0\")\n",
    "\n",
    "    conv5_1_W_conv2d = tf.get_default_graph().get_tensor_by_name(\"conv5_1/W_conv2d:0\")\n",
    "    conv5_1_b_conv2d = tf.get_default_graph().get_tensor_by_name(\"conv5_1/b_conv2d:0\")\n",
    "    conv5_2_W_conv2d = tf.get_default_graph().get_tensor_by_name(\"conv5_2/W_conv2d:0\")\n",
    "    conv5_2_b_conv2d = tf.get_default_graph().get_tensor_by_name(\"conv5_2/b_conv2d:0\")\n",
    "    conv5_3_W_conv2d = tf.get_default_graph().get_tensor_by_name(\"conv5_3/W_conv2d:0\")\n",
    "    conv5_3_b_conv2d = tf.get_default_graph().get_tensor_by_name(\"conv5_3/b_conv2d:0\")\n",
    "\n",
    "    fc6_relu_W = tf.get_default_graph().get_tensor_by_name(\"fc6_relu/W:0\")\n",
    "    fc6_relu_b = tf.get_default_graph().get_tensor_by_name(\"fc6_relu/b:0\")\n",
    "    fc7_relu_W = tf.get_default_graph().get_tensor_by_name(\"fc7_relu/W:0\")\n",
    "    fc7_relu_b = tf.get_default_graph().get_tensor_by_name(\"fc7_relu/b:0\")\n",
    "    #fc8不要\n",
    "    \n",
    "    dict = {\n",
    "        #左边是原模型的名字，右边是新模型的引用\n",
    "        \"vgg_16/conv1/conv1_1/weights\": conv1_1_W_conv2d,\n",
    "        \"vgg_16/conv1/conv1_1/biases\": conv1_1_b_conv2d,\n",
    "        \"vgg_16/conv1/conv1_2/weights\": conv1_2_W_conv2d,\n",
    "        \"vgg_16/conv1/conv1_2/biases\": conv1_2_b_conv2d,\n",
    "\n",
    "        \"vgg_16/conv2/conv2_1/weights\": conv2_1_W_conv2d,\n",
    "        \"vgg_16/conv2/conv2_1/biases\": conv2_1_b_conv2d,\n",
    "        \"vgg_16/conv2/conv2_2/weights\": conv2_2_W_conv2d,\n",
    "        \"vgg_16/conv2/conv2_2/biases\": conv2_2_b_conv2d,\n",
    "\n",
    "        \"vgg_16/conv3/conv3_1/weights\": conv3_1_W_conv2d,\n",
    "        \"vgg_16/conv3/conv3_1/biases\": conv3_1_b_conv2d,\n",
    "        \"vgg_16/conv3/conv3_2/weights\": conv3_2_W_conv2d,\n",
    "        \"vgg_16/conv3/conv3_2/biases\": conv3_2_b_conv2d,\n",
    "        \"vgg_16/conv3/conv3_3/weights\": conv3_3_W_conv2d,\n",
    "        \"vgg_16/conv3/conv3_3/biases\": conv3_3_b_conv2d,\n",
    "\n",
    "        \"vgg_16/conv4/conv4_1/weights\": conv4_1_W_conv2d,\n",
    "        \"vgg_16/conv4/conv4_1/biases\": conv4_1_b_conv2d,\n",
    "        \"vgg_16/conv4/conv4_2/weights\": conv4_2_W_conv2d,\n",
    "        \"vgg_16/conv4/conv4_2/biases\": conv4_2_b_conv2d,\n",
    "        \"vgg_16/conv4/conv4_3/weights\": conv4_3_W_conv2d,\n",
    "        \"vgg_16/conv4/conv4_3/biases\": conv4_3_b_conv2d,\n",
    "\n",
    "        \"vgg_16/conv5/conv5_1/weights\": conv5_1_W_conv2d,\n",
    "        \"vgg_16/conv5/conv5_1/biases\": conv5_1_b_conv2d,\n",
    "        \"vgg_16/conv5/conv5_2/weights\": conv5_2_W_conv2d,\n",
    "        \"vgg_16/conv5/conv5_2/biases\": conv5_2_b_conv2d,\n",
    "        \"vgg_16/conv5/conv5_3/weights\": conv5_3_W_conv2d,\n",
    "        \"vgg_16/conv5/conv5_3/biases\": conv5_3_b_conv2d,\n",
    "\n",
    "        \"vgg_16/fc6/weights\": fc6_relu_W,\n",
    "        \"vgg_16/fc6/biases\": fc6_relu_b,\n",
    "        \"vgg_16/fc7/weights\": fc7_relu_W,\n",
    "        \"vgg_16/fc7/biases\": fc7_relu_b\n",
    "        }\n",
    "    return dict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from F:/Python/pre-trained/vgg_16.ckpt\n",
      "load ok!\n"
     ]
    }
   ],
   "source": [
    "d = prepare()\n",
    "# 读取ckpt里保存的参数\n",
    "sess = tf.InteractiveSession()\n",
    "#注意，你回头去看原模型和新模型的全连接层的shape不一样，所以下面可以开启reshape = True\n",
    "saver = tf.train.Saver(max_to_keep=2, var_list=d, reshape=True)\n",
    "\n",
    "saver.restore(sess, pre_trained_dir + \"vgg_16.ckpt\")\n",
    "print(\"load ok!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_dir = \"C:/Users/hsqyc/Desktop/\"\n",
    "filename = final_dir + \"dogVScat_train_vgg_tfrecord\"\n",
    "\n",
    "print(\"Converting data into %s ...\" % filename)\n",
    "#     with tf.Session() as sess:\n",
    "\n",
    "writer = tf.python_io.TFRecordWriter(filename)\n",
    "\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(coord=coord)\n",
    "i = 0\n",
    "try:\n",
    "    while not coord.should_stop():\n",
    "        A, B = sess.run([y_ ,train_label_batch_run])\n",
    "        for index in range(len(B)):\n",
    "            image = A[index]\n",
    "            image = image.reshape(4096, )\n",
    "            img_raw = image.tostring()  # tobytes()\n",
    "\n",
    "            label = int(B[index])\n",
    "            #             img_raw = image.tostring()#tobytes()\n",
    "\n",
    "            example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                \"label\": tf.train.Feature(int64_list=tf.train.Int64List(value=[label])),\n",
    "                #                 \"img_w\": tf.train.Feature(int64_list=tf.train.Int64List(value=[img_w])),\n",
    "                #                 \"img_h\": tf.train.Feature(int64_list=tf.train.Int64List(value=[img_h])),\n",
    "                \"img_raw\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_raw])),\n",
    "            }))\n",
    "            writer.write(example.SerializeToString())  # Serialize To String\n",
    "            print(i)\n",
    "            i += 1\n",
    "except tf.errors.OutOfRangeError:\n",
    "    print('done!')\n",
    "finally:\n",
    "    coord.request_stop()\n",
    "writer.close()\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.assign(\"conv1_1/b_conv2d\",reader.get_tensor(\"vgg_16/conv1/conv1_2/biases\"))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
